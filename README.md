# Tracking-system

The target detection algorithm is developped for use on a raspberry pi as the form factor of the computer is perfect to place in a remote controlled plane as it is as light as it is small but still packs a lot of computing power which is perfect to run the algorithm efficiently.

The target detection is a fairly simple algorithm once we understand the steps that go towards making the algorithm function, but despite the simplicity, it yields accurate and quick results making it perfect for our selected use case.

The first step of the algorithm is the retrieval of the image, and the solution to this problem is the libcamera-still command that allows us to start a preview of the camera feed and by having our code send user defined signals to the running libcamera application, we can take pictures that are to be used for the next step of the algorithm which is the actual detection of the target within the image.

Now, it is important to note that the target we are detecting is a bright red round target of a predetermined size, and considering that the algorithm is meant to detect the target within an image taken from a camera stuck to a plane, knowing the altitude of the plane, we can use basic geometry and trigonometry to calculate the perceived size of the target in the image.
With this, we can detect the target based on three criteria, which are color, shape and size. Therefore, the algorithm I developped performs three procedures to detect the target and the first of these procedures is the binarization of the retrieved image based on the R, G and B values of each pixels. More precisely, it turns any pixel with R value higher than 160, B less than 100 and G less than 100 white so that the next procedures operate on this new binarized image. The goal of this binarization is to isolate the characteristics of our target in the image so that we have the highest possible chance of retrieving the actual target.

The next procedure is the one that finds the circular target of size R within the image, and it does so by scanning the entire image from left to right, top to bottom and assumes that any white pixel it comes accross defines where the top of a potential target is, and using the radius we calculated as R in this function x = sqrt(-y^(2)+R), we can calculate the width that the circle should be at any y position within that circle. Using  y = {-R, -R + 1, ..., R - 1, R}, and consequently x = {-sqrt(-y^(2)+R), -sqrt(-y^(2)+R) + 1, ..., sqrt(-y^(2)+R) - 1, sqrt(-y^(2)+R)}, we count how many pixels are white at every x and y position within the circle. Note that to reduce the processing time of the algorithm, we can get away with checking only every (R / n)th pixel, with an n typically around 4 for higher probability of not missing the target and providing a sizeable speed improvement, as even considering the margin of error in our calculation of perceived target radius, our algorithm's scanning of the image will practically always land on a white pixel from our target.

Then, with the list of potential target positions and count of how many white pixels corresponded with our target mask for each potential target, we select the target with the highest count as our true target.

However, there is still one last operation that needs to be performed to find the true center of the detected target as we currently have no way of guaranteeing that the target position that was calculated is the actual center of the target as the calculation for R could be off and we calculated only every (R / n)th pixel. Therefore, we perform a simple top-down and left-right edge detection and average the resulting values to get a better approximate of the targets position.
